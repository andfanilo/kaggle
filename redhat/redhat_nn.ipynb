{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning Redhat version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = df[0:2197291]\n",
    "x_test = df.tail(2695977 - 2197290)\n",
    "#x_train = df.head(1000)\n",
    "#x_test = df.tail(1000)\n",
    "\n",
    "y_train = x_train[\"outcome\"]\n",
    "act_train = x_train[\"activity_id\"]\n",
    "act_test = x_test[\"activity_id\"]\n",
    "del x_train['outcome']\n",
    "del x_test['outcome']\n",
    "del x_train['activity_id']\n",
    "del x_test['activity_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFlearn - all numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m0.84601\u001b[0m\u001b[0m\n",
      "| RMSProp | epoch: 030 | loss: 0.84601 - binary_acc: 0.4672 -- iter: 1000/1000\n",
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m0.84601\u001b[0m\u001b[0m\n",
      "| RMSProp | epoch: 030 | loss: 0.84601 - binary_acc: 0.4672 -- iter: 1000/1000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    # Build neural network\n",
    "    net = tflearn.input_data(shape=[None, len(x_train.columns)])\n",
    "    net = tflearn.fully_connected(net, 32, activation='relu', weights_init='uniform')\n",
    "    net = tflearn.fully_connected(net, 16, activation='relu', weights_init='uniform')\n",
    "    net = tflearn.fully_connected(net, 1, activation='sigmoid')\n",
    "    \n",
    "    net = tflearn.regression(net, loss=\"binary_crossentropy\", optimizer='rmsprop', metric=\"accuracy\")\n",
    "\n",
    "    # Define model\n",
    "    model = tflearn.DNN(net)\n",
    "\n",
    "    # Start training\n",
    "    model.fit(x_train.values, np.reshape(y_train, (len(y_train), 1)), batch_size=32, n_epoch=30, show_metric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Keras - all numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=len(x_train.columns), activation=\"relu\", init=\"uniform\"))\n",
    "model.add(Dense(16, activation=\"relu\", init=\"uniform\"))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.8050 - acc: 0.5210     \n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6289 - acc: 0.6360     \n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.6013 - acc: 0.6670     \n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.5182 - acc: 0.7570     \n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.4894 - acc: 0.7470     \n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.4510 - acc: 0.7770     \n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.4293 - acc: 0.8250     \n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.3850 - acc: 0.8310     \n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.3757 - acc: 0.8560     \n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s - loss: 0.3737 - acc: 0.8390     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a64183908>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train.values, y_train, batch_size=32, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras - categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "from sklearn.feature_extraction import FeatureHasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureHasher(dtype=<class 'numpy.float64'>, input_type='dict',\n",
       "       n_features=1024, non_negative=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = FeatureHasher(n_features=1024)\n",
    "h.fit(x_train.as_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e6704f9485da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/miniconda3/envs/datalab/lib/python3.4/site-packages/sklearn/feature_extraction/hashing.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_X, y)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mraw_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dict\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mraw_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_iteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "h.transform(x_train.as_matrix)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:datalab]",
   "language": "python",
   "name": "conda-env-datalab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
